{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d2f3e4a",
      "metadata": {
        "id": "5d2f3e4a"
      },
      "source": [
        "# AutoPilotTuiML testing funcs\n",
        "The main goal of this notebook is only to debug and test fucntions from the package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec3b08d",
      "metadata": {
        "id": "1ec3b08d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tuiautopilotml.wrappers import *\n",
        "from tuiautopilotml.autopilot_mode import autopilot_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f55f1b2",
      "metadata": {
        "id": "0f55f1b2"
      },
      "outputs": [],
      "source": [
        "# # Use only sample from csv\n",
        "\n",
        "clf_df = pd.read_csv('sample_datasets/classification.csv' , index_col = 0 )\n",
        "target_label_cf = 'segment'\n",
        "clf_df = clf_df[:10000]\n",
        "clf_df_with_missing = clf_df.copy()\n",
        "# generate missing values\n",
        "for i in range(0,len(clf_df),10):\n",
        "    clf_df_with_missing.replace(clf_df_with_missing.AveragePricePaid[i],np.nan,inplace=True)\n",
        "\n",
        "# reg_df = pd.read_csv('sample_datasets/regression.csv' , parse_dates = True)\n",
        "# target_label_reg = 'clicks'\n",
        "# reg_df = reg_df[:5000]\n",
        "\n",
        "# # generate missing values\n",
        "# for i in range(0,len(reg_df),20):\n",
        "#     reg_df.replace(reg_df.impressions[i],np.nan,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aa0bb7f",
      "metadata": {
        "id": "9aa0bb7f"
      },
      "source": [
        "## TESTING FUNCTIONS SET 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45249731",
      "metadata": {
        "id": "45249731"
      },
      "outputs": [],
      "source": [
        "# Init params \n",
        "\n",
        "# model = RandomForestRegressor()\n",
        "# classification = False\n",
        "# evaluation_metric = 'neg_mean_squared_error'\n",
        "# dataframe = reg_df.copy()\n",
        "# target_label = 'clicks'\n",
        "# date_cols = ['departure_date'] \n",
        "\n",
        "model = RandomForestClassifier()\n",
        "classification = True\n",
        "evaluation_metric= 'accuracy'\n",
        "dataframe = clf_df\n",
        "target_label = 'segment'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8cdee4",
      "metadata": {
        "id": "fb8cdee4",
        "outputId": "8b2c08fb-3660-4c35-c22e-e20216ab6fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 1\n",
            "Converting columns to lowercase\n",
            "Ran 3 checks on the dataframe\n",
            "All the checks were passed..\n",
            "Your dataframe seems to be correct. We return the original input data\n",
            "Converting columns to lowercase\n",
            "There are missing values in your dataset\n",
            "Ran 3 checks on the dataframe\n",
            "Sanity checks FAILED: (failures=1)\n",
            "Converting to int float and dates\n",
            "Column being processed: mosaic\n",
            "Column being processed: avg_leadtime\n",
            "Convert to float avg_leadtime\n",
            "Column being processed: averageflightduration_imputedvalue\n",
            "Convert to float averageflightduration_imputedvalue\n",
            "Column being processed: averagepricepaid\n",
            "Convert to float averagepricepaid\n",
            "Column being processed: busyness\n",
            "Convert to float busyness\n",
            "Column being processed: basicholidaycostperpax_imputedvalue\n",
            "Convert to float basicholidaycostperpax_imputedvalue\n",
            "Column being processed: averagespendperactiveyear\n",
            "Convert to float averagespendperactiveyear\n",
            "Column being processed: pricesensitivity\n",
            "Convert to float pricesensitivity\n",
            "Column being processed: totalrevenue\n",
            "Convert to float totalrevenue\n",
            "Column being processed: pricedifference\n",
            "Convert to float pricedifference\n",
            "Column being processed: tratingnew\n",
            "Convert to float tratingnew\n",
            "Column being processed: correctedholidayduration_imputedvalue\n",
            "Convert to int correctedholidayduration_imputedvalue\n",
            "Column being processed: frequency\n",
            "Convert to float frequency\n",
            "Column being processed: activeperiod\n",
            "Convert to float activeperiod\n",
            "Column being processed: household_income___median_income\n",
            "Convert to int household_income___median_income\n",
            "Column being processed: affluence\n",
            "Convert to int affluence\n",
            "Column being processed: urbanity___generalised_urbanity_measure\n",
            "Convert to float urbanity___generalised_urbanity_measure\n",
            "Column being processed: rurality___remoteness_from_high_streets\n",
            "Convert to float rurality___remoteness_from_high_streets\n",
            "Column being processed: sum_isweb\n",
            "Convert to int sum_isweb\n",
            "Column being processed: boardscore\n",
            "Convert to float boardscore\n",
            "Column being processed: countryname.spain\n",
            "Convert to float countryname.spain\n",
            "Column being processed: boardbasisoffersdescription.all.inclusive\n",
            "Convert to float boardbasisoffersdescription.all.inclusive\n",
            "Column being processed: haultype.mid\n",
            "Convert to float haultype.mid\n",
            "Column being processed: destinationloyalty\n",
            "Convert to float destinationloyalty\n",
            "Column being processed: sum_isretail\n",
            "Convert to int sum_isretail\n",
            "Column being processed: brandloyalty\n",
            "Convert to float brandloyalty\n",
            "Column being processed: haultype.short\n",
            "Convert to float haultype.short\n",
            "Column being processed: haulloyalty\n",
            "Convert to float haulloyalty\n",
            "Column being processed: avg_issummer\n",
            "Convert to float avg_issummer\n",
            "Column being processed: boardbasisoffersdescription.half.board\n",
            "Convert to float boardbasisoffersdescription.half.board\n",
            "Column being processed: months\n",
            "Convert to int months\n",
            "Column being processed: segment\n"
          ]
        }
      ],
      "source": [
        "#The following function is not is use\n",
        "\n",
        "# Skip this function \n",
        "\n",
        "# print('Part 0')\n",
        "# key_path = '/Users/carlosdelacruz/Desktop/main_folders/passwords_keys/keywords.txt'\n",
        "# base = '/Users/carlosdelacruz/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml_notebooks/sql_files/'\n",
        "# sql_file_location = base + 'needs_oct_dec.sql'\n",
        "# extract_from_database_to_df(sql_file_location = sql_file_location, mode ='from_database', \n",
        "#                                  new_file_title ='traveller_features_oct_dec',\n",
        "#                                  type_of_connection='snowflake', save_to_csv = True, \n",
        "#                                  sf_password_file_location=key_path, sf_user_name='CARLOS_DELACRUZ', \n",
        "#                                  sf_account='tuinordic.eu-central-1',sf_role='SYSADMIN')\n",
        "\n",
        "print('Part 1')\n",
        "transformed_df = dataframe_transformation(dataframe, cols_to_exclude=None,  drop_missing_values=False)                       \n",
        "transformed_df_with_missing = dataframe_transformation(clf_df_with_missing, cols_to_exclude=None,  drop_missing_values=False)                       \n",
        "\n",
        "t1 = shuffle_order_save(dataframe, shuffle=False, sample_size=100, save_sample_df=False )\n",
        "t2 = shuffle_order_save(dataframe, shuffle=True, sample_size=100, save_sample_df=False )\n",
        "\n",
        "print('Part 2')\n",
        "n_estimators = [100, 200]\n",
        "xgb_param_grid = dict( n_estimators=n_estimators )\n",
        "func = get_cross_val_score_wrapper\n",
        "func2 = grid_search_wrapper\n",
        "model_training_estimator_wrapper(func= func2, dataframe= transformed_df[:700], split_pct_param=0.01, patience_limit=0.2, target_label = target_label, param_grid=xgb_param_grid ,model = model, \n",
        "                                 evaluation_metric=\"accuracy\", n_jobs=-1, verbose = 3, n_folds=3, n_repeats=3,\n",
        "                                 k_fold_method='stratified_k_fold', grid_search_method='randomized', random_state=seed)\n",
        "                        \n",
        "\n",
        "print('Part 3')\n",
        "\n",
        "\n",
        "initial_eda_wrapper(dataframe=transformed_df, target_label = target_label, summary_report = False,\n",
        "                         return_outliers = False , distribution = 'non_gaussian' , \n",
        "                     save_figures = False)\n",
        "\n",
        "initial_eda_wrapper(dataframe=transformed_df, target_label = target_label, summary_report = False, \n",
        "                        return_outliers = True , distribution = 'non_gaussian' , \n",
        "                     save_figures = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a146fa0a",
      "metadata": {
        "id": "a146fa0a"
      },
      "source": [
        "## TESTING FUNCTIONS SET 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d997db",
      "metadata": {
        "scrolled": false,
        "id": "57d997db",
        "outputId": "6eb727d6-8bd3-4b89-b7c7-69d2f0e515b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 6\n",
            "Label encode and one hot encode only objects\n"
          ]
        }
      ],
      "source": [
        " print('Part 4')\n",
        "X,y = get_splits_wrapper(dataframe = transformed_df, target_label =target_label , train_split=False, scaled=False, scaler=StandardScaler(),\n",
        "                     validation_set=False , test_size = 0.2)\n",
        "\n",
        "\n",
        "print('Part 5')\n",
        "imputation_df = eval_imputation_method_wrapper(dataframe= transformed_df_with_missing, target_label= target_label, model=model, \n",
        "                                     classification=classification, evaluation_metric=evaluation_metric)\n",
        "\n",
        "\n",
        "print('Part 6')\n",
        "samp_df_encoded = get_encoded_wrapper(transformed_df) \n",
        "\n",
        "print(samp_df_encoded.shape)\n",
        "samp_df_encoded2, map_ = get_encoded_wrapper(transformed_df, return_mapping =True) \n",
        "nulls_encoded,map_ = get_encoded_wrapper(transformed_df_with_missing, encode_nulls=True, return_mapping=True)\n",
        "\n",
        "\n",
        "print('Part 7')\n",
        "#OBS: XGBOOST WILL NOT RETURN VALUES WITH A SMALL DATASET , EX: 500\n",
        "  \n",
        "scalers_scores1, output_df1 = eval_model_scaler_wrapper(dataframe=samp_df_encoded[:1000], target_label=target_label, model_name='KNN', k_fold_method='k_fold', n_folds=3,\n",
        "                             n_repeats=10,\n",
        "                             classification=classification,\n",
        "                             evaluation_metric=evaluation_metric)\n",
        "\n",
        "print('Part 7.1')\n",
        "scalers_scores2, output_df2= eval_model_scaler_wrapper(dataframe=samp_df_encoded[:1000], target_label=target_label, model_name='KNN', k_fold_method='repeated_k_fold', n_folds=3,\n",
        "                             n_repeats=3,\n",
        "                             classification=classification,\n",
        "                             evaluation_metric=evaluation_metric)\n",
        "\n",
        "\n",
        "print('Part 8')\n",
        "outliers_scores1,outliers_df1 = handle_outliers(dataframe = samp_df_encoded[:1000], target_label=target_label, tot_outlier_pct=15, model= RandomForestClassifier(),\n",
        "                         test_size=0.2)\n",
        "\n",
        "outliers_scores2,outliers_df2  = handle_outliers(dataframe = samp_df_encoded[:1000],distribution=None, target_label=target_label, tot_outlier_pct=5, model= RandomForestClassifier(),\n",
        "                         test_size=0.2)\n",
        "\n",
        "\n",
        "print('Part 9')\n",
        "feature_importance1 = get_feature_importance_wrapper(dataframe=samp_df_encoded , target_label=target_label ,method = 'rf' , classification = classification,\n",
        "                                        n_features = 5 \n",
        "                            , save_figure = False )\n",
        "\n",
        "feature_importance2 = get_feature_importance_wrapper(dataframe=samp_df_encoded , target_label=target_label ,method = 'xgb' , classification = classification, n_features = 2 ,\n",
        "                                  penalty = \"l2\" ,  save_figure = False )\n",
        "\n",
        "print('Part 10')    \n",
        "\n",
        "oversamplers1 = evaluate_oversamplers(dataframe=samp_df_encoded, target_label=target_label,classification=True, evaluation_metric='accuracy',  test_size=0.2, method='random_os', \n",
        "                      class_threshold=5,\n",
        "                          model=model,random_state=0 )\n",
        "\n",
        "oversamplers2 = evaluate_oversamplers(dataframe=samp_df_encoded, target_label=target_label, test_size=0.2, method='smote_os', \n",
        "                      class_threshold=5,model=model,random_state=0 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740706f1",
      "metadata": {
        "id": "740706f1"
      },
      "source": [
        "## TESTING FUNCTIONS SET 3 (train vs test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae86b3fa",
      "metadata": {
        "id": "ae86b3fa",
        "outputId": "2b7a2e4e-1169-40ec-efde-5b262068a458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part train vs test \n",
            "Current folds: [0, 2000, 4000, 6000, 8000]\n",
            "Label encode and one hot encode only objects\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for fold 0: [0.4860957850953448, 0.006786581004938409]\n",
            "Label encode and one hot encode only objects\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for fold 1: [0.4927663669366858, 0.013370698625128914]\n",
            "Label encode and one hot encode only objects\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for fold 2: [0.5056172095916173, 0.022639800438454837]\n",
            "Label encode and one hot encode only objects\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for fold 3: [0.46903843571049153, 0.012984277164318402]\n",
            "Mean score: 0.48837944933353483, Standard deviation: 0.01318782919107137\n",
            "Current folds: [0, 2000, 4000, 6000, 8000]\n",
            "Train shape(2000, 32)\n",
            "Label encode and one hot encode only objects\n",
            "Col:Mosaic\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Mosaic in fold 0: [0.49672379054226035, 0.015717375552562345]\n",
            "Col:Avg_LeadTime\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Avg_LeadTime in fold 0: [0.49467314211593766, 0.015227734234843329]\n",
            "Col:AverageFlightDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AverageFlightDuration_ImputedValue in fold 0: [0.4982993999047567, 0.015160377155462515]\n",
            "Col:AveragePricePaid\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AveragePricePaid in fold 0: [0.5280214619590358, 0.013432768835110277]\n",
            "Col:Busyness\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Busyness in fold 0: [0.5118730713774684, 0.011260160091884613]\n",
            "Col:BasicHolidayCostperPAX_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BasicHolidayCostperPAX_ImputedValue in fold 0: [0.49385029845574796, 0.00726167939512583]\n",
            "Col:AverageSpendPerActiveYear\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AverageSpendPerActiveYear in fold 0: [0.4740385937470258, 0.010214672249031215]\n",
            "Col:PriceSensitivity\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceSensitivity in fold 0: [0.48300682223193975, 0.014305714506523636]\n",
            "Col:TotalRevenue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TotalRevenue in fold 0: [0.4893365613240631, 0.014664878639367008]\n",
            "Col:PriceDifference\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceDifference in fold 0: [0.48549015222656855, 0.017102424610684175]\n",
            "Col:TRatingNew\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TRatingNew in fold 0: [0.5167458038520695, 0.009668069447908502]\n",
            "Col:CorrectedHolidayDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CorrectedHolidayDuration_ImputedValue in fold 0: [0.4882291778910286, 0.00590611133664147]\n",
            "Col:Frequency\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Frequency in fold 0: [0.4894445737414489, 0.017704957909871154]\n",
            "Col:ActivePeriod\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for ActivePeriod in fold 0: [0.4976484087684206, 0.013361805847365137]\n",
            "Col:Household_income___Median_income\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Household_income___Median_income in fold 0: [0.48976942874384405, 0.022353501344267564]\n",
            "Col:Affluence\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Affluence in fold 0: [0.4958601479213396, 0.020614077844084755]\n",
            "Col:Urbanity___Generalised_urbanity_measure\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Urbanity___Generalised_urbanity_measure in fold 0: [0.5039501161418539, 0.013569185042887082]\n",
            "Col:Rurality___Remoteness_from_high_streets\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Rurality___Remoteness_from_high_streets in fold 0: [0.49275230658055164, 0.011563718808323274]\n",
            "Col:Sum_IsWeb\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Sum_IsWeb in fold 0: [0.49904686517766617, 0.017056174122732266]\n",
            "Col:BoardScore\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardScore in fold 0: [0.5038485144900343, 0.01120304996470764]\n",
            "Col:CountryName.Spain\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CountryName.Spain in fold 0: [0.5017193728054015, 0.0064397803782800835]\n",
            "Col:BoardBasisOffersDescription.All.Inclusive\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardBasisOffersDescription.All.Inclusive in fold 0: [0.5023222575573506, 0.014460484444920712]\n",
            "Col:HaulType.Mid\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulType.Mid in fold 0: [0.5162285449461796, 0.01373010655151887]\n",
            "Col:DestinationLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for DestinationLoyalty in fold 0: [0.49942350326436447, 0.016946299737868327]\n",
            "Col:Sum_IsRetail\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Sum_IsRetail in fold 0: [0.5122996861396472, 0.012155592585854864]\n",
            "Col:BrandLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BrandLoyalty in fold 0: [0.4892176868430978, 0.010047444867808326]\n",
            "Col:HaulType.Short\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulType.Short in fold 0: [0.48944539831698997, 0.0030978158708732995]\n",
            "Col:HaulLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulLoyalty in fold 0: [0.4890277206032983, 0.00864756565065973]\n",
            "Col:Avg_IsSummer\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Avg_IsSummer in fold 0: [0.5078402763610101, 0.009525736830021959]\n",
            "Col:BoardBasisOffersDescription.Half.Board\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for BoardBasisOffersDescription.Half.Board in fold 0: [0.49421725183072046, 0.012836099364386611]\n",
            "Col:Months\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Months in fold 0: [0.47167023415593007, 0.013836078133616701]\n",
            "Col:Segment\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Segment in fold 0: [0.4896689052998336, 0.018527226231838657]\n",
            "Train shape(2000, 32)\n",
            "Label encode and one hot encode only objects\n",
            "Col:Mosaic\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Mosaic in fold 1: [0.5043781599011338, 0.016247092177376937]\n",
            "Col:Avg_LeadTime\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Avg_LeadTime in fold 1: [0.5043491362655024, 0.025122983776035127]\n",
            "Col:AverageFlightDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AverageFlightDuration_ImputedValue in fold 1: [0.5071076424804191, 0.016621177454794158]\n",
            "Col:AveragePricePaid\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AveragePricePaid in fold 1: [0.4973193192817719, 0.013727439460330879]\n",
            "Col:Busyness\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Busyness in fold 1: [0.48748982638022265, 0.019258026037754467]\n",
            "Col:BasicHolidayCostperPAX_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BasicHolidayCostperPAX_ImputedValue in fold 1: [0.48682823959947485, 0.002981536323494695]\n",
            "Col:AverageSpendPerActiveYear\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AverageSpendPerActiveYear in fold 1: [0.4814025368987938, 0.0224603278336136]\n",
            "Col:PriceSensitivity\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceSensitivity in fold 1: [0.49963271052707636, 0.016022422489948195]\n",
            "Col:TotalRevenue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TotalRevenue in fold 1: [0.5032834254133978, 0.018714172015495037]\n",
            "Col:PriceDifference\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceDifference in fold 1: [0.49315004332487866, 0.01982491109180384]\n",
            "Col:TRatingNew\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TRatingNew in fold 1: [0.4944827068125, 0.00927994676316755]\n",
            "Col:CorrectedHolidayDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CorrectedHolidayDuration_ImputedValue in fold 1: [0.49913320603411454, 0.014169338931254293]\n",
            "Col:Frequency\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Frequency in fold 1: [0.5054091115825287, 0.02096775377395564]\n",
            "Col:ActivePeriod\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for ActivePeriod in fold 1: [0.503380920586387, 0.012093555484924159]\n",
            "Col:Household_income___Median_income\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Household_income___Median_income in fold 1: [0.4759941051979205, 0.01211585165175024]\n",
            "Col:Affluence\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Affluence in fold 1: [0.47679191762425627, 0.014677841894299071]\n",
            "Col:Urbanity___Generalised_urbanity_measure\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Urbanity___Generalised_urbanity_measure in fold 1: [0.495721903841018, 0.007755649073666108]\n",
            "Col:Rurality___Remoteness_from_high_streets\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Rurality___Remoteness_from_high_streets in fold 1: [0.4916254857808779, 0.012844510756118456]\n",
            "Col:Sum_IsWeb\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Sum_IsWeb in fold 1: [0.49559069594413074, 0.012357195171733386]\n",
            "Col:BoardScore\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardScore in fold 1: [0.5039669266266792, 0.021164721533642388]\n",
            "Col:CountryName.Spain\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CountryName.Spain in fold 1: [0.5007205332520441, 0.008346307006288318]\n",
            "Col:BoardBasisOffersDescription.All.Inclusive\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardBasisOffersDescription.All.Inclusive in fold 1: [0.5070699225650585, 0.008936482076806062]\n",
            "Col:HaulType.Mid\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulType.Mid in fold 1: [0.5194036943246807, 0.017192374655305705]\n",
            "Col:DestinationLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for DestinationLoyalty in fold 1: [0.508484444334977, 0.01239633368322961]\n",
            "Col:Sum_IsRetail\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Sum_IsRetail in fold 1: [0.49925794009734303, 0.015147167673777613]\n",
            "Col:BrandLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BrandLoyalty in fold 1: [0.4932433670789256, 0.0205377497566369]\n",
            "Col:HaulType.Short\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulType.Short in fold 1: [0.497919566790345, 0.014271163293882352]\n",
            "Col:HaulLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulLoyalty in fold 1: [0.4890490749605285, 0.012724312186098685]\n",
            "Col:Avg_IsSummer\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Avg_IsSummer in fold 1: [0.49233403750256144, 0.008822735803833028]\n",
            "Col:BoardBasisOffersDescription.Half.Board\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardBasisOffersDescription.Half.Board in fold 1: [0.48322953373985317, 0.019136564163467675]\n",
            "Col:Months\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Months in fold 1: [0.5024767408987946, 0.009991182509752543]\n",
            "Col:Segment\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Segment in fold 1: [0.5217663290424225, 0.02199286603660534]\n",
            "Train shape(2000, 32)\n",
            "Label encode and one hot encode only objects\n",
            "Col:Mosaic\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Mosaic in fold 2: [0.49955681296708915, 0.01853737513481034]\n",
            "Col:Avg_LeadTime\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Avg_LeadTime in fold 2: [0.5107589010590361, 0.03134633158906407]\n",
            "Col:AverageFlightDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for AverageFlightDuration_ImputedValue in fold 2: [0.5098411935500785, 0.014157868401165176]\n",
            "Col:AveragePricePaid\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for AveragePricePaid in fold 2: [0.49585351644922326, 0.017517165686830843]\n",
            "Col:Busyness\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Busyness in fold 2: [0.5014396668798972, 0.01782210672544079]\n",
            "Col:BasicHolidayCostperPAX_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.04 minutes to run\n",
            "Score for BasicHolidayCostperPAX_ImputedValue in fold 2: [0.5067271425200147, 0.0048291060039563245]\n",
            "Col:AverageSpendPerActiveYear\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for AverageSpendPerActiveYear in fold 2: [0.5053164614359394, 0.010662467276273298]\n",
            "Col:PriceSensitivity\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceSensitivity in fold 2: [0.5026647870905943, 0.011253080749817393]\n",
            "Col:TotalRevenue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TotalRevenue in fold 2: [0.5165700820407834, 0.018243221755997113]\n",
            "Col:PriceDifference\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceDifference in fold 2: [0.48873984051321795, 0.014412366205639474]\n",
            "Col:TRatingNew\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TRatingNew in fold 2: [0.49169706234226335, 0.01260844149958011]\n",
            "Col:CorrectedHolidayDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CorrectedHolidayDuration_ImputedValue in fold 2: [0.5059416705429317, 0.01860394334893537]\n",
            "Col:Frequency\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Frequency in fold 2: [0.4935032570765773, 0.022533091959907325]\n",
            "Col:ActivePeriod\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for ActivePeriod in fold 2: [0.4851936037059003, 0.019199616270484464]\n",
            "Col:Household_income___Median_income\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Household_income___Median_income in fold 2: [0.5007559162732609, 0.016364624853916362]\n",
            "Col:Affluence\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Affluence in fold 2: [0.4979934138056706, 0.016317820482186652]\n",
            "Col:Urbanity___Generalised_urbanity_measure\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Urbanity___Generalised_urbanity_measure in fold 2: [0.5216568053899419, 0.01336349204868009]\n",
            "Col:Rurality___Remoteness_from_high_streets\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Rurality___Remoteness_from_high_streets in fold 2: [0.5155485164228243, 0.014474517175086176]\n",
            "Col:Sum_IsWeb\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Sum_IsWeb in fold 2: [0.5076200874866076, 0.030665694408377575]\n",
            "Col:BoardScore\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardScore in fold 2: [0.5007178623611753, 0.018799404156957814]\n",
            "Col:CountryName.Spain\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for CountryName.Spain in fold 2: [0.5166280779582575, 0.01996653877948499]\n",
            "Col:BoardBasisOffersDescription.All.Inclusive\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BoardBasisOffersDescription.All.Inclusive in fold 2: [0.5013494661127197, 0.01488119240294617]\n",
            "Col:HaulType.Mid\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulType.Mid in fold 2: [0.5040063393501283, 0.014155624104363603]\n",
            "Col:DestinationLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for DestinationLoyalty in fold 2: [0.5098156721944223, 0.010074167414963663]\n",
            "Col:Sum_IsRetail\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Sum_IsRetail in fold 2: [0.5177483967685697, 0.020125402413986873]\n",
            "Col:BrandLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BrandLoyalty in fold 2: [0.5010792992283296, 0.012989972729411174]\n",
            "Col:HaulType.Short\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for HaulType.Short in fold 2: [0.5095038279410187, 0.020477988801001133]\n",
            "Col:HaulLoyalty\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for HaulLoyalty in fold 2: [0.49950898849555436, 0.01552165049950286]\n",
            "Col:Avg_IsSummer\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Avg_IsSummer in fold 2: [0.5203333922260038, 0.013878751283598095]\n",
            "Col:BoardBasisOffersDescription.Half.Board\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for BoardBasisOffersDescription.Half.Board in fold 2: [0.4926968715925117, 0.004584303422580939]\n",
            "Col:Months\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Months in fold 2: [0.4743523883768316, 0.011831425159826024]\n",
            "Col:Segment\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Segment in fold 2: [0.5008484939932191, 0.019470049653943965]\n",
            "Train shape(2000, 32)\n",
            "Label encode and one hot encode only objects\n",
            "Col:Mosaic\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for Mosaic in fold 3: [0.47066068273162626, 0.011780649762893293]\n",
            "Col:Avg_LeadTime\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Avg_LeadTime in fold 3: [0.502976844434671, 0.022988802906357235]\n",
            "Col:AverageFlightDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for AverageFlightDuration_ImputedValue in fold 3: [0.4884657415487933, 0.01547462301303252]\n",
            "Col:AveragePricePaid\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for AveragePricePaid in fold 3: [0.5054022038287213, 0.008062643432194514]\n",
            "Col:Busyness\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for Busyness in fold 3: [0.5033778873075594, 0.02250052050411689]\n",
            "Col:BasicHolidayCostperPAX_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for BasicHolidayCostperPAX_ImputedValue in fold 3: [0.4912889933631873, 0.025703778386941056]\n",
            "Col:AverageSpendPerActiveYear\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for AverageSpendPerActiveYear in fold 3: [0.5058393508794393, 0.016575275095858072]\n",
            "Col:PriceSensitivity\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceSensitivity in fold 3: [0.48064045616697737, 0.00855205180613289]\n",
            "Col:TotalRevenue\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for TotalRevenue in fold 3: [0.5050928502945865, 0.013099619042965902]\n",
            "Col:PriceDifference\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for PriceDifference in fold 3: [0.49695369901061676, 0.023468024618334693]\n",
            "Col:TRatingNew\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "Score for TRatingNew in fold 3: [0.48818267641032326, 0.01575774842777205]\n",
            "Col:CorrectedHolidayDuration_ImputedValue\n",
            "Collecting garbage...\n",
            "The process took: 0.03 minutes to run\n",
            "Score for CorrectedHolidayDuration_ImputedValue in fold 3: [0.4957202719618016, 0.015791026812921664]\n",
            "Col:Frequency\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/by/pt5_hysn0lb75x63vpgqbtsw0000gn/T/ipykernel_71200/1060063804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# test_comp.train_test_pairplot()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtest_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_covariance_shift_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Segment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcov_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_covariance_shift_score_per_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_score_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/wrappers.py\u001b[0m in \u001b[0;36mget_covariance_shift_score_per_feature\u001b[0;34m(self, estimator, cov_score_thresh, n_folds, n_repeats, random_state)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                                      \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                                                      \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                                                      evaluation_metric='roc_auc')\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Score for {col} in fold {fold}: {scores}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/helper_functions.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcurrent_time_minutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/helper_functions.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Collecting garbage...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/helper_functions.py\u001b[0m in \u001b[0;36mget_cross_val_score_wrapper\u001b[0;34m(dataframe, target_label, x, y, model, multiple_eval_scores, k_fold_method, n_folds, n_repeats, random_state, classification, multi_classif, evaluation_metric, n_jobs, verbose)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0mcv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cross_validation_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# To ensure this function continues to do what it originally did, we take the means here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/cross_validation.py\u001b[0m in \u001b[0;36mget_cross_validation_scores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEvalMetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             scores = ms.cross_val_score(self.model, self.dataset.inputs, self.dataset.labels, cv=self.policy,\n\u001b[0;32m--> 301\u001b[0;31m                                         scoring=metric.value, n_jobs=self.config.n_jobs, verbose=self.config.verbose)\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCrossValidationResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    448\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 256\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print('Part train vs test ')\n",
        "\n",
        "train, test = train_test_split_from_df(dataframe, 0.2)\n",
        "test_comp = TrainVsTest(train,test)\n",
        "test_comp.get_report('Segment')\n",
        "test_comp.get_train_test_distribution()\n",
        "test_comp.get_train_test_counts()\n",
        "a, b = test_comp.is_distribution_different()\n",
        "full_data = test_comp.get_is_train_col()\n",
        "test_comp.train_test_pairplot()\n",
        "mean_score, std  = test_comp.get_covariance_shift_score(target_label = 'Segment')\n",
        "cov_scores, drop_list = test_comp.get_covariance_shift_score_per_feature(cov_score_thresh=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "583919ab",
      "metadata": {
        "id": "583919ab"
      },
      "source": [
        "## TESTING FUNCTIONS SET 3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4e7c81",
      "metadata": {
        "scrolled": false,
        "id": "2d4e7c81",
        "outputId": "0f06200b-d4a0-4c9c-decb-f7378a10e7c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 15\n",
            "Model name: XGB, Parameters: {'n_estimators': <hyperopt.pyll.base.Apply object at 0x7f8b080a1c50>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x7f8b080a1f90>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x7f8b080a91d0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x7f8b080a9490>}\n",
            "[07:47:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[07:47:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[07:47:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "Collecting garbage...                                                           \n",
            "The process took: 0.3 minutes to run                                            \n",
            "Accuracy: 0.625020229810649                                                     \n",
            "  1%|▏         | 1/80 [00:18<23:43, 18.02s/trial, best loss: -0.625020229810649]\n",
            "optimization complete\n",
            "Results:{'XGB': (0.625020229810649, 0.019659251376223486)}\n"
          ]
        }
      ],
      "source": [
        "print('Part 13')\n",
        "\n",
        "multi_scores_df = evaluate_models_wrapper(dataframe=samp_df_encoded[:1000], target_label='segment', models_list=models_list_default, classification=True, multiple_eval_scores=True, stacking=True)\n",
        "\n",
        "evaluate_models_wrapper(dataframe=samp_df_encoded[:1000], target_label='segment', models_list=models_list_default, classification=True, multiple_eval_scores=False, stacking=True)\n",
        "\n",
        "\n",
        "print('Part 13.1 Reduced features score')\n",
        "\n",
        "scores_redcued_features = get_reduced_features_cv_scores(samp_df_encoded, target_label, model)\n",
        "\n",
        "\n",
        "print('Part 14')\n",
        "\n",
        "n_estimators = [100, 200, 300, 400, 500]\n",
        "\n",
        "xgb_param_grid = dict(n_estimators=n_estimators)\n",
        "            \n",
        "\n",
        "X_scaled,y = get_splits_wrapper(dataframe = samp_df_encoded, target_label =target_label , train_split=False, scaled=True, scaler=StandardScaler(),\n",
        "                      validation_set=False , test_size = 0.2)\n",
        "\n",
        "output_grid_s = grid_search_wrapper(dataframe=samp_df_encoded , target_label = target_label,model= model, param_grid = xgb_param_grid, \n",
        "                             evaluation_metric=evaluation_metric, n_jobs=-1, verbose = 3, n_folds=3, n_repeats=3,\n",
        "                        k_fold_method='stratified_k_fold', grid_search_method='randomized', random_state= seed)\n",
        "\n",
        "print('Part 15')   \n",
        "results_list = hyper_opt_manual(dataframe= samp_df_encoded[:1000], target_label= target_label, model_name='XGB', max_evals=80, k_fold_method='k_fold', n_folds=3,\n",
        "                    n_repeats=2, classification=True, evaluation_metric='accuracy', timeout_minutes=0.5, n_jobs=-1,\n",
        "                    verbose=0)\n",
        "\n",
        "print('Part 15.1')  \n",
        "func = hyper_opt_manual\n",
        "\n",
        "ml_flow_wrapper(func=func,model_name='test_model_name', evaluation_metric = 'accuracy',dataframe= samp_df_encoded[:1000], target_label= target_label, model_name='XGB', max_evals=80, k_fold_method='k_fold', n_folds=3,\n",
        "                    n_repeats=2, classification=True, evaluation_metric='accuracy', timeout_minutes=0.5, n_jobs=-1,\n",
        "                    verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e642711a",
      "metadata": {
        "id": "e642711a"
      },
      "source": [
        "## TESTING FUNCTIONS SET 4 (functions are not updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5542dd4d",
      "metadata": {
        "id": "5542dd4d"
      },
      "outputs": [],
      "source": [
        "# # RUN THIS CODE FIRST \n",
        "\n",
        "# def mlp_hyperopt_wrapper(X_train, X_valid, y_train, y_valid, X_test, y_test, activation_f_type='multiclass' ,classification=True, \n",
        "#                          metrics ='accuracy',monitor='val_loss', mode='min',hl_activation='relu',verbose=3, \n",
        "#                          patience=3,max_evals=100 , timeout_minutes=10):\n",
        "    \n",
        "#     if y_train.nunique() != y_valid.nunique():\n",
        "#         print(f' y_train and y _valid should have the same size')\n",
        "\n",
        "#     if activation_f_type == 'classif':\n",
        "#         o_activation = 'sigmoid'\n",
        "#         loss = 'binary_crossentropy'\n",
        "\n",
        "#     elif activation_f_type == 'multiclass':\n",
        "#         o_activation = 'softmax'\n",
        "#         loss = 'categorical_crossentropy'\n",
        "\n",
        "#     elif activation_f_type == 'reg':\n",
        "#         o_activation = 'linear'  # relu \n",
        "#         loss = 'mean_squared_error'\n",
        "\n",
        "#     timeout = timeout_minutes * 60\n",
        "#     space = get_initial_dicts(mode='hyperparams', params_list='MLP', classification=classification)['MLP']\n",
        "\n",
        "\n",
        "#     def hyperparameters(space):\n",
        "#         input_n = space['input_n']\n",
        "#         output_n = int(y_train.nunique())\n",
        "#         n_neurons = int(np.sqrt(input_n * output_n)* input_n)\n",
        "#         print(input_n)\n",
        "#         print(n_neurons)\n",
        "#         print(space)\n",
        "\n",
        "#         model = Sequential()\n",
        "\n",
        "#         #model.add(Dense(units=space['units1'], input_dim=X_train.shape[1], activation=hl_activation))  # input layer\n",
        "#         model.add(Dense(units=n_neurons/2.5, input_dim=X_train.shape[1], activation=hl_activation))  # input layer\n",
        "\n",
        "#         model.add(Dropout(space['dropout1']))\n",
        "\n",
        "#         #model.add(Dense(units=space['units2'], activation=hl_activation))\n",
        "#         model.add(Dense(units=n_neurons/5.5, input_dim=X_train.shape[1], activation=hl_activation))  # input layer\n",
        "\n",
        "#         model.add(Dropout(space['dropout2']))\n",
        "\n",
        "#         model.add(Dense(int(y_train.nunique()), activation=o_activation))  # output layer\n",
        "\n",
        "#         model.compile(loss= loss, optimizer=space['optimizer'], metrics=[metrics])\n",
        "#         early_stop = EarlyStopping(monitor=monitor, mode=mode, verbose=verbose, patience=patience)\n",
        "\n",
        "#         print('Fit model...')\n",
        "#         # transform y \n",
        "#         y_train_cat = tf.keras.utils.to_categorical(y_train)\n",
        "#         y_valid_cat = tf.keras.utils.to_categorical(y_valid)\n",
        "\n",
        "#         model.fit(X_train, y_train_cat, epochs=space['epochs'], verbose=verbose, callbacks=[early_stop],\n",
        "#                   batch_size=space['batch_size'], validation_data=(X_valid, y_valid_cat))\n",
        "\n",
        "#         print('Predict...')\n",
        "#         prediction = model.predict(X_test, batch_size=space['batch_size'], verbose=verbose)\n",
        "#         prediction = np.argmax(prediction, axis=1)\n",
        "#         score = accuracy_score(y_test, prediction)\n",
        "#         print('Accuracy:', score)\n",
        "\n",
        "#         return {'loss': -score, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "#     trials = Trials()\n",
        "\n",
        "#     best = fmin(fn=hyperparameters,\n",
        "#                 space=space,\n",
        "#                 algo=tpe.suggest,\n",
        "#                 max_evals=max_evals,\n",
        "#                 trials=trials,\n",
        "#                 timeout=timeout\n",
        "#                 )\n",
        "#     print('optimization complete')\n",
        "#     best_model = trials.results[np.argmin([r['loss'] for r in\n",
        "#                                            trials.results])]\n",
        "\n",
        "#     best_score = best_model['loss'] * -1 \n",
        "#     #params = best_model['model'].get_params()#[algorithm]\n",
        "\n",
        "#     return best_score,trials\n",
        "\n",
        "\n",
        "# def mlp_basemodel_wrapper(X_train, X_valid, y_train, y_valid, activation_f_type = 'classif' , optimizer = 'adam' ,\n",
        "#                           regulator = 10,\n",
        "#                           hl_activation = 'relu', epochs = 100 , batch_size = 128 ,metrics = 'accuracy',\n",
        "#                           metric_to_monitor = 'val_loss', mode = 'minimize', patience = 10, verbose = 1  ):\n",
        "#     \"\"\"\n",
        "#     MLP for baseline model creation \n",
        "#     \"\"\"\n",
        "#     print(f'Numeber of features: {X_train.shape[1]}')\n",
        "\n",
        "#     input_n = X_train.shape[1]\n",
        "#     output_n = int(y_train.nunique())\n",
        "    \n",
        "#     if activation_f_type == 'classif':\n",
        "#         o_activation = 'sigmoid'\n",
        "#         loss='binary_crossentropy'\n",
        "    \n",
        "#     elif  activation_f_type == 'multiclass':\n",
        "#         o_activation = 'softmax'\n",
        "#         loss='categorical_crossentropy'\n",
        "    \n",
        "#     elif  activation_f_type == 'reg':\n",
        "#         o_activation = 'linear'# relu \n",
        "#         loss='mean_squared_error'\n",
        "    \n",
        "#     print(f'Activation function used for output layer: {o_activation}')\n",
        "    \n",
        "#     n_neurons = int(np.sqrt(input_n * output_n)* regulator)\n",
        "#     print(f'Number of neurons: {n_neurons}-{int(n_neurons/2.5)}-{int(n_neurons/5.5)}')\n",
        "\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(n_neurons, input_dim = input_n, activation= hl_activation))# input layer \n",
        "\n",
        "#     model.add(Dropout(0.3))\n",
        "    \n",
        "#     model.add(Dense(int(n_neurons/2.5), activation= hl_activation))\n",
        "#     model.add(Dropout(0.3))\n",
        "    \n",
        "#     model.add(Dense(int(n_neurons/5.5) , activation=hl_activation))\n",
        "#     model.add(Dropout(0.1))\n",
        "    \n",
        "#     model.add(Dense(output_n, activation= o_activation))# output layer \n",
        "    \n",
        "    \n",
        "#     model.compile(loss=loss, optimizer = optimizer, metrics=[metrics])\n",
        "#     early_stop = EarlyStopping(monitor = metric_to_monitor, mode = mode, verbose = verbose, patience = patience)\n",
        "#     print('Fit model...')\n",
        "    \n",
        "#     print(f'converting y{y_train.shape}')\n",
        "#     y_valid = tf.keras.utils.to_categorical(y_valid)\n",
        "#     y_train = tf.keras.utils.to_categorical(y_train)\n",
        "    \n",
        "#     print(f'converted y{y_train.shape}')\n",
        "#     model.fit(X_train, y_train, epochs = epochs , verbose = verbose , callbacks=[early_stop] , \n",
        "#               batch_size = batch_size , validation_data= (X_valid,y_valid ) )\n",
        "    \n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee38c003",
      "metadata": {
        "id": "ee38c003"
      },
      "outputs": [],
      "source": [
        "# print('Part 16') \n",
        "# X_train, X_valid, y_train, y_valid , X_test, y_test = get_splits_wrapper(dataframe = samp_df_encoded,\n",
        "#                                                                          target_label = target_label, train_split=True\n",
        "#                        ,validation_set=True , test_size = 0.2 , scaled=True , scaler= MinMaxScaler())\n",
        "\n",
        "# best_score, trials = mlp_hyperopt_wrapper(X_train, X_valid, y_train, y_valid , X_test, y_test ,hl_activation='relu', \n",
        "#                      activation_f_type='classif', patience= 1 ,max_evals =100, timeout_minutes = 2,\n",
        "#                                           monitor='val_accuracy', mode='max', )\n",
        "\n",
        "\n",
        "# print('Part 17')   \n",
        "# X, y  = get_splits_wrapper(dataframe = samp_df_encoded, target_label = 'segment', train_split=False\n",
        "#                       ,validation_set=False , test_size = 0.2 , scaled=True , scaler= MinMaxScaler())\n",
        "\n",
        "# best_params, best_score, study = optuna_wrapper(dataframe=samp_df_encoded,target_label=target_label,algorithm='XGB', \n",
        "#                                   params_list= ['n_estimators' ,'max_depth' , 'learning_rate'],\n",
        "#        n_minutes_limit= 1 , n_trials = 15  )\n",
        "\n",
        "\n",
        "# print('Part 18')   \n",
        "# neural_net_model = mlp_basemodel_wrapper(X_train, X_valid, y_train, y_valid, optimizer = 'adam' , \n",
        "#                                          hl_activation = 'relu', activation_f_type='multiclass' ,\n",
        "#                                          epochs = 200 , batch_size = 128, patience = 10, regulator= 100 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929e2f07",
      "metadata": {
        "id": "929e2f07"
      },
      "source": [
        "# TESTING FUNCTIONS SECTION\n",
        "This sections does not have any particular structure. Its main goal is to use it to test functions in different orders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef592cb",
      "metadata": {
        "id": "7ef592cb"
      },
      "source": [
        "## AUTOPILOT FUCNTIONS\n",
        "This section tests all functions related to the autopilot mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1af3d5f",
      "metadata": {
        "id": "f1af3d5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# output_dict, output_df = handle_outliers(dataframe = samp_df_encoded[:1000], target_label=target_label, tot_outlier_pct=15, model= RandomForestClassifier(),\n",
        "#                          test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2948cbf9",
      "metadata": {
        "id": "2948cbf9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# acc_score = get_random_os_score(dataframe=samp_df_encoded[:100000], target_label=target_label,  classification= True, model= model, test_size=0.2,\n",
        "#                         class_threshold=5, evaluation_metric='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde6172e",
      "metadata": {
        "id": "bde6172e"
      },
      "outputs": [],
      "source": [
        "##### 'Work in progress' #####\n",
        "\n",
        "\n",
        "\n",
        "# scores, output_df  = evaluate_oversamplers(dataframe=samp_df_encoded[:100000], target_label=target_label, classification=True,\n",
        "#                                       evaluation_metric='accuracy', test_size=0.2, method='smote_os',\n",
        "#                                       class_threshold=5,\n",
        "#                                       model=model, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "593f9aba",
      "metadata": {
        "id": "593f9aba"
      },
      "source": [
        "## Autopilot mode testing\n",
        "This section is only dedicated to the autopilot mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa0ae4a",
      "metadata": {
        "id": "baa0ae4a"
      },
      "outputs": [],
      "source": [
        "# IDEA: break this down into several dictionaries and combine into 1 \n",
        "\n",
        "CONFIG = {\n",
        "    'run_id_number': np.random.randint(1,100), \n",
        "    'dataframe': clf_df_with_missing[:3000],#dataframe[:3000],\n",
        "    'latest_df': pd.DataFrame(),\n",
        "    'df_with_missing': clf_df_with_missing,\n",
        "    'cols_to_exclude': None,\n",
        "    'drop_missing_values': False,\n",
        "    'encoded_df': samp_df_encoded,\n",
        "    'baseline_model_name': 'baseline_model_score',\n",
        "    'target_label': 'segment',\n",
        "    'scaled_df': True,\n",
        "    'scaler': scalers['Standard'],\n",
        "    'multi_classif': False,\n",
        "    'stacking': True,\n",
        "    'distribution': 'non_gaussian',\n",
        "    'tot_outlier_pct': 13,\n",
        "    'classification': True,\n",
        "    'evaluation_metric': 'accuracy',\n",
        "    'multiple_eval_scores': False,\n",
        "    'models_list': models_list_default,\n",
        "    'model': RandomForestClassifier(random_state = seed),\n",
        "    'model_name': 'RF',\n",
        "    'test_size': 0.2,\n",
        "    'k_fold_method': 'k_fold',\n",
        "    'n_folds': 5,\n",
        "    'n_repeats': 10,\n",
        "    'seed': 0,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': 0,\n",
        "    'max_evals': 80,\n",
        "    'timeout_minutes': 1, \n",
        "    'class_threshold': 5\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5e8f49",
      "metadata": {
        "id": "cc5e8f49",
        "outputId": "61dead51-0f46-4f8b-a875-34ed06edaddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current run id: 31\n",
            "updating params\n",
            "*********JOB:0: dataframe_transformation*********\n",
            "Converting columns to lowercase\n",
            "There are missing values in your dataset\n",
            "Ran 3 checks on the dataframe\n",
            "Sanity checks FAILED: (failures=1)\n",
            "Converting to int float and dates\n",
            "Column being processed: mosaic\n",
            "Column being processed: avg_leadtime\n",
            "Convert to float avg_leadtime\n",
            "Column being processed: averageflightduration_imputedvalue\n",
            "Convert to float averageflightduration_imputedvalue\n",
            "Column being processed: averagepricepaid\n",
            "Convert to float averagepricepaid\n",
            "Column being processed: busyness\n",
            "Convert to float busyness\n",
            "Column being processed: basicholidaycostperpax_imputedvalue\n",
            "Convert to float basicholidaycostperpax_imputedvalue\n",
            "Column being processed: averagespendperactiveyear\n",
            "Convert to float averagespendperactiveyear\n",
            "Column being processed: pricesensitivity\n",
            "Convert to float pricesensitivity\n",
            "Column being processed: totalrevenue\n",
            "Convert to float totalrevenue\n",
            "Column being processed: pricedifference\n",
            "Convert to float pricedifference\n",
            "Column being processed: tratingnew\n",
            "Convert to float tratingnew\n",
            "Column being processed: correctedholidayduration_imputedvalue\n",
            "Convert to int correctedholidayduration_imputedvalue\n",
            "Column being processed: frequency\n",
            "Convert to float frequency\n",
            "Column being processed: activeperiod\n",
            "Convert to float activeperiod\n",
            "Column being processed: household_income___median_income\n",
            "Convert to int household_income___median_income\n",
            "Column being processed: affluence\n",
            "Convert to int affluence\n",
            "Column being processed: urbanity___generalised_urbanity_measure\n",
            "Convert to float urbanity___generalised_urbanity_measure\n",
            "Column being processed: rurality___remoteness_from_high_streets\n",
            "Convert to float rurality___remoteness_from_high_streets\n",
            "Column being processed: sum_isweb\n",
            "Convert to int sum_isweb\n",
            "Column being processed: boardscore\n",
            "Convert to float boardscore\n",
            "Column being processed: countryname.spain\n",
            "Convert to float countryname.spain\n",
            "Column being processed: boardbasisoffersdescription.all.inclusive\n",
            "Convert to float boardbasisoffersdescription.all.inclusive\n",
            "Column being processed: haultype.mid\n",
            "Convert to float haultype.mid\n",
            "Column being processed: destinationloyalty\n",
            "Convert to float destinationloyalty\n",
            "Column being processed: sum_isretail\n",
            "Convert to int sum_isretail\n",
            "Column being processed: brandloyalty\n",
            "Convert to float brandloyalty\n",
            "Column being processed: haultype.short\n",
            "Convert to float haultype.short\n",
            "Column being processed: haulloyalty\n",
            "Convert to float haulloyalty\n",
            "Column being processed: avg_issummer\n",
            "Convert to float avg_issummer\n",
            "Column being processed: boardbasisoffersdescription.half.board\n",
            "Convert to float boardbasisoffersdescription.half.board\n",
            "Column being processed: months\n",
            "Convert to int months\n",
            "Column being processed: segment\n",
            "Updating config dataframe_transformation...\n",
            "updating params\n",
            "*********JOB:1: handle_missing_values*********\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "[0.13166666666666665]\n",
            "Training fold: 1\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "[0.13166666666666665, 0.6166666666666667]\n",
            "Training fold: 2\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "[0.13166666666666665, 0.6166666666666667, 0.65]\n",
            "Training fold: 3\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy median\n",
            "Label encode and one hot encode only objects\n",
            "[0.13166666666666665, 0.6166666666666667, 0.65, 0.6566666666666666]\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "[0.13833333333333334]\n",
            "Training fold: 1\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "[0.13833333333333334, 0.615]\n",
            "Training fold: 2\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "[0.13833333333333334, 0.615, 0.6533333333333333]\n",
            "Training fold: 3\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy mean\n",
            "Label encode and one hot encode only objects\n",
            "[0.13833333333333334, 0.615, 0.6533333333333333, 0.6566666666666666]\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "[0.13666666666666666]\n",
            "Training fold: 1\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.13666666666666666, 0.6333333333333333]\n",
            "Training fold: 2\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "[0.13666666666666666, 0.6333333333333333, 0.65]\n",
            "Training fold: 3\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "[0.13666666666666666, 0.6333333333333333, 0.65, 0.66]\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "[0.135]\n",
            "Training fold: 1\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "[0.135, 0.6066666666666667]\n",
            "Training fold: 2\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "[0.135, 0.6066666666666667, 0.6433333333333333]\n",
            "Training fold: 3\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "Columns with missing values: ['averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy constant\n",
            "Label encode and one hot encode only objects\n",
            "[0.135, 0.6066666666666667, 0.6433333333333333, 0.6416666666666667]\n",
            "drop_score...\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "Label encode and one hot encode only objects\n",
            "Label encode and one hot encode only objects\n",
            "[0.13653846153846153]\n",
            "Training fold: 1\n",
            "Label encode and one hot encode only objects\n",
            "Label encode and one hot encode only objects\n",
            "[0.13653846153846153, 0.6374045801526718]\n",
            "Training fold: 2\n",
            "Label encode and one hot encode only objects\n",
            "Label encode and one hot encode only objects\n",
            "[0.13653846153846153, 0.6374045801526718, 0.6316793893129771]\n",
            "Training fold: 3\n",
            "Label encode and one hot encode only objects\n",
            "Label encode and one hot encode only objects\n",
            "[0.13653846153846153, 0.6374045801526718, 0.6316793893129771, 0.6393129770992366]\n",
            "Encoding nulls...\n",
            "Label encode and one hot encode only objects\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "[0.6383333333333333]\n",
            "Training fold: 1\n",
            "[0.6383333333333333, 0.6183333333333333]\n",
            "Training fold: 2\n",
            "[0.6383333333333333, 0.6183333333333333, 0.6183333333333333]\n",
            "Training fold: 3\n",
            "[0.6383333333333333, 0.6183333333333333, 0.6183333333333333, 0.6466666666666666]\n",
            "Results: {'get_imputed_x-median': (0.51375, 0.22111577849624392), 'get_imputed_x-mean': (0.5158333333333334, 0.2185638096503831), 'get_imputed_x-most_frequent': (0.52, 0.2215225095159005), 'get_imputed_x-constant': (0.5066666666666667, 0.2150807341958415), 'drop_score-': (0.5112338520258367, 0.21634872198634422)}\n",
            "Current best method: get_imputed_x-most_frequent\n",
            "Columns with missing values: ['averageflightduration_imputedvalue', 'averagepricepaid', 'basicholidaycostperpax_imputedvalue', 'averagespendperactiveyear', 'totalrevenue', 'activeperiod']\n",
            "Running strategy most_frequent\n",
            "Label encode and one hot encode only objects\n",
            "Updating config handle_missing_values...\n",
            "updating params\n",
            "*********JOB:2: encoding*********\n",
            "Label encode and one hot encode only objects\n",
            "Updating config encoding...\n",
            "updating params\n",
            "*********JOB:3: baseline_score*********\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.7s remaining:   13.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.7s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting garbage...\n",
            "The process took: 0.17 minutes to run\n",
            "Logging sklearn artifacts...\n",
            "Find your results here: http://localhost:5000/\n",
            "Score: 0.6463333333333333 Std:0.010718623460542332\n",
            "updating params\n",
            "*********JOB:4: handle_outliers*********\n",
            "Replace values\n",
            "mean\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "[0.6666666666666666]\n",
            "Training fold: 1\n",
            "[0.6666666666666666, 0.6333333333333333]\n",
            "Training fold: 2\n",
            "[0.6666666666666666, 0.6333333333333333, 0.6633333333333333]\n",
            "Training fold: 3\n",
            "[0.6666666666666666, 0.6333333333333333, 0.6633333333333333, 0.6466666666666666]\n",
            "median\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "[0.6666666666666666]\n",
            "Training fold: 1\n",
            "[0.6666666666666666, 0.6133333333333333]\n",
            "Training fold: 2\n",
            "[0.6666666666666666, 0.6133333333333333, 0.6416666666666667]\n",
            "Training fold: 3\n",
            "[0.6666666666666666, 0.6133333333333333, 0.6416666666666667, 0.6366666666666667]\n",
            "Drop values\n",
            "[0, 600, 1200, 1800, 2400]\n",
            "Training fold: 0\n",
            "[0.645]\n",
            "Training fold: 1\n",
            "[0.645, 0.6033333333333334]\n",
            "Training fold: 2\n",
            "[0.645, 0.6033333333333334, 0.615]\n",
            "Training fold: 3\n",
            "[0.645, 0.6033333333333334, 0.615, 0.6383333333333333]\n",
            "General scores: {'replace_outliers-mean': (0.6525, 0.01341123078285924), 'replace_outliers-median': (0.6395833333333333, 0.018943446536115512), 'drop_outliers-': (0.6254166666666667, 0.01693020804492502)}\n",
            "***********Generating final output***********\n",
            "Current best method: replace_outliers-mean\n",
            "Calculating standard cross_validation with best method...\n",
            "Collecting garbage...\n",
            "The process took: 0.05 minutes to run\n",
            "Results:[0.6533333333333333, 0.019888578520235057]\n",
            "obtaining latest score..\n",
            "Previous scores: (0.6463333333333333, 0.010718623460542332)\n",
            "We keep previous results since the new results are not significant\n",
            "updating params\n",
            "*********JOB:5: evaluate_oversamplers*********\n",
            "***********Checking imbalance degree***********\n",
            "Overall entropy score: 0.8151772762989967\n",
            "Moderate imbalanced classes: {0: 0.19566666666666666, 3: 0.187}\n",
            "Extreme imbalanced classes: {0: 0.19566666666666666, 3: 0.187} \n",
            "***********Running smote_os***********\n",
            "Running smote_os...\n",
            "***********Running random_os***********\n",
            "Generating internal x,y\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "y counts:{6: 36.13333333333333, 0: 19.566666666666666, 3: 18.7, 2: 9.633333333333335, 4: 7.666666666666666, 7: 5.766666666666667, 5: 1.866666666666667, 1: 0.6666666666666667}\n",
            "Classes to re sample: [3, 4]\n",
            "Current percentile value 155\n",
            "Failed with 35 percentile\n",
            "Current percentile value 172\n",
            "Failed with 40 percentile\n",
            "Current percentile value 188\n",
            "Failed with 45 percentile\n",
            "Current percentile value 204\n",
            "Failed with 50 percentile\n",
            "Current percentile value 220\n",
            "Failed with 55 percentile\n",
            "Current percentile value 273\n",
            "Failed with 60 percentile\n",
            "Current percentile value 353\n",
            "Failed with 65 percentile\n",
            "Current percentile value 433\n",
            "Failed with 70 percentile\n",
            "Current percentile value 459\n",
            "Current percentile value 155\n",
            "Failed with 35 percentile\n",
            "Current percentile value 172\n",
            "Failed with 40 percentile\n",
            "Current percentile value 188\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.62      0.66       120\n",
            "           2       0.71      0.60      0.65        62\n",
            "           3       0.60      0.43      0.50       104\n",
            "           4       0.63      0.25      0.36        48\n",
            "           5       0.50      0.17      0.25         6\n",
            "           6       0.63      0.90      0.74       220\n",
            "           7       0.86      0.75      0.80        40\n",
            "\n",
            "    accuracy                           0.66       600\n",
            "   macro avg       0.66      0.53      0.57       600\n",
            "weighted avg       0.66      0.66      0.64       600\n",
            "\n",
            "PART 2: Plotting figures \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 155} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 172} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 188} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 204} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 220} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 273} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 353} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 433} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 459} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 155} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 172} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 188} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 459, 4: 188} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PART 5: Make the prediction. Evaluate only on test data\n",
            "Kappa score: 0.5567750105529758\n",
            "PART 6: Plot\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.61      0.65       120\n",
            "           2       0.71      0.63      0.67        62\n",
            "           3       0.62      0.41      0.50       104\n",
            "           4       0.85      0.35      0.50        48\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.64      0.91      0.75       220\n",
            "           7       0.89      0.80      0.84        40\n",
            "\n",
            "    accuracy                           0.67       600\n",
            "   macro avg       0.63      0.53      0.56       600\n",
            "weighted avg       0.68      0.67      0.66       600\n",
            "\n",
            "***********Generating final output***********\n",
            "Current best method: random_os\n",
            "Generating internal x,y\n",
            "Collecting garbage...\n",
            "The process took: 0.02 minutes to run\n",
            "y counts:{6: 36.13333333333333, 0: 19.566666666666666, 3: 18.7, 2: 9.633333333333335, 4: 7.666666666666666, 7: 5.766666666666667, 5: 1.866666666666667, 1: 0.6666666666666667}\n",
            "Classes to re sample: [3, 4]\n",
            "Current percentile value 198\n",
            "Failed with 35 percentile\n",
            "Current percentile value 218\n",
            "Failed with 40 percentile\n",
            "Current percentile value 238\n",
            "Failed with 45 percentile\n",
            "Current percentile value 259\n",
            "Failed with 50 percentile\n",
            "Current percentile value 280\n",
            "Failed with 55 percentile\n",
            "Current percentile value 343\n",
            "Failed with 60 percentile\n",
            "Current percentile value 438\n",
            "Failed with 65 percentile\n",
            "Current percentile value 533\n",
            "Failed with 70 percentile\n",
            "Current percentile value 567\n",
            "Current percentile value 198\n",
            "Failed with 35 percentile\n",
            "Current percentile value 218\n",
            "Failed with 40 percentile\n",
            "Current percentile value 238\n",
            "obtaining latest score..\n",
            "Previous scores: (0.6463333333333333, 0.010718623460542332)\n",
            "Results are significant, updating config...\n",
            "Uploading config to MLFLOW...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 198} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 218} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 238} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 259} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 280} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 343} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 438} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 533} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 567} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 198} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 218} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={4: 238} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/imblearn/utils/_validation.py:591: FutureWarning: Pass sampling_strategy={3: 567, 4: 238} as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "ename": "MlflowException",
          "evalue": "Got invalid value None for metric 'std' (timestamp=1638975467915). Please specify value as a valid double (64-bit floating point)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/by/pt5_hysn0lb75x63vpgqbtsw0000gn/T/ipykernel_40141/4201638480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpipe_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodelling_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mpost_modelling_steps\u001b[0m  \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mautopilot_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe_steps\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/autopilot_mode.py\u001b[0m in \u001b[0;36mautopilot_mode\u001b[0;34m(steps, config_dict)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     update_upload_config(scores=scores, config_dict=config_dict, result_df=result_df,\n\u001b[1;32m     62\u001b[0m                                          run_name=f'{run_id_number}_{functions_names[i]}_stage')\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/helper_functions.py\u001b[0m in \u001b[0;36mupdate_upload_config\u001b[0;34m(scores, config_dict, result_df, tuned_params, run_name)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'We keep previous results since the new results are not significant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/main_folders/DSProjects/AutopilotProject/tuiautopilotml/tuiautopilotml/mlflow_uploader.py\u001b[0m in \u001b[0;36mupload_config_file\u001b[0;34m(self, run_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evaluation_metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'std'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mlog_metric\u001b[0;34m(key, value, step)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \"\"\"\n\u001b[1;32m    440\u001b[0m     \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_or_start_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mlog_metric\u001b[0;34m(self, run_id, key, value, timestamp, step)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \"\"\"\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mlog_metric\u001b[0;34m(self, run_id, key, value, timestamp, step)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0m_validate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/mlflow/utils/validation.py\u001b[0m in \u001b[0;36m_validate_metric\u001b[0;34m(key, value, timestamp, step)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;34m\"Got invalid value %s for metric '%s' (timestamp=%s). Please specify value as a valid \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;34m\"double (64-bit floating point)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mINVALID_PARAMETER_VALUE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMlflowException\u001b[0m: Got invalid value None for metric 'std' (timestamp=1638975467915). Please specify value as a valid double (64-bit floating point)"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ................................ score: (test=0.632) total time=   2.6s\n",
            "[CV] END ................................ score: (test=0.655) total time=   1.0s\n",
            "[CV] END ................................ score: (test=0.643) total time=   2.7s\n",
            "[CV] END ................................ score: (test=0.640) total time=   2.5s\n",
            "[CV] END ................................ score: (test=0.662) total time=   2.6s\n"
          ]
        }
      ],
      "source": [
        "##### 'WORK IN PROGRESS' #####\n",
        "\n",
        "default_steps = {'dataframe_transformation': dataframe_transformation,\n",
        "                'handle_missing_values': eval_imputation_method_wrapper, \n",
        "                 'encoding': get_encoded_wrapper,\n",
        "                 'baseline_score': get_baseline_score \n",
        "                 } \n",
        "\n",
        "modelling_steps = {'handle_outliers': handle_outliers,'evaluate_oversamplers':evaluate_oversamplers, 'evaluate_models':evaluate_models_wrapper}  \n",
        "\n",
        "post_modelling_steps = {'transformation_methods': eval_model_scaler_wrapper, 'hyper_param_opt': hyper_opt_manual}\n",
        "\n",
        "pipe_steps = {**default_steps, **modelling_steps, ** post_modelling_steps  }  \n",
        "\n",
        "autopilot_mode(steps=pipe_steps , config_dict = CONFIG )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72691f1d",
      "metadata": {
        "id": "72691f1d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd81a7b6",
      "metadata": {
        "id": "bd81a7b6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366ea80f",
      "metadata": {
        "id": "366ea80f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bca535",
      "metadata": {
        "id": "73bca535"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b005903",
      "metadata": {
        "id": "7b005903"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53384bee",
      "metadata": {
        "id": "53384bee"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95fd7452",
      "metadata": {
        "id": "95fd7452"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a5fe8a2",
      "metadata": {
        "id": "7a5fe8a2"
      },
      "source": [
        "# ************Apendix code************\n",
        "This section of the notebook contains experimental approaches "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca7cd34",
      "metadata": {
        "id": "3ca7cd34"
      },
      "outputs": [],
      "source": [
        "def get_cols_cardinality(dataframe,n_max_categories):\n",
        "\n",
        "    cols = [cname for cname in dataframe if dataframe[cname].nunique() <= n_max_categories and\n",
        "                            dataframe[cname].dtype == \"object\"]\n",
        "    return cols\n",
        "\n",
        "\n",
        "class Figures:\n",
        "\n",
        "    def __init__(self, input_data, target_label, asc=False, fig_title=f'Fig Title',\n",
        "                 x_title='X_axis_title', y_title='Y_axis_title', stage='current stage'):\n",
        "        \"\"\"Avalable stages: Exploratory Data Analysis ,Feature Engineering \"\"\"\n",
        "        self.input_data = input_data\n",
        "        self.target_label = target_label\n",
        "        self.asc = asc\n",
        "        self.fig_title = fig_title\n",
        "        self.x_title = x_title\n",
        "        self.y_title = y_title\n",
        "        self.stage = stage\n",
        "     \n",
        "  \n",
        "class OtherPLots(Figures):\n",
        "#     def __init__(self):\n",
        "#         pass\n",
        "\n",
        "    def correlation_heatmap(self,figsize=(12, 7) ,palette=None , save_figure=False):\n",
        "        print('Correlation between variables')\n",
        "        plt.figure(figsize=figsize)\n",
        "        sns.heatmap(self.input_data.corr(), cmap=palette, fmt='g', annot=False)\n",
        "        if save_figure:\n",
        "            save_figure_to_disk(main_folder=self.stage, figure_name= self.fig_title , save_as_plt = True)\n",
        "        plt.show()\n",
        "\n",
        "    def combination_plot(self,palette=None,save_figure=False ):\n",
        "        train, test = train_test_split_from_df(dataframe,test_size)\n",
        "\n",
        "        int_float_cols = self.input_data.select_dtypes([int, float]).columns\n",
        "        plt.figure(figsize=(10, (len(int_float_cols)) * 2 + 3))  # width , height\n",
        "\n",
        "        count = 1\n",
        "        for col in int_float_cols:\n",
        "            # Row 2\n",
        "            plt.subplot(len(int_float_cols), 2, count)  # n_rows , n columns , index\n",
        "            sns.boxplot(x=col, y=self.target_label, data=self.input_data, palette=palette)\n",
        "            count += 1\n",
        "\n",
        "            # Row 2\n",
        "            plt.subplot(len(int_float_cols), 2, count)\n",
        "            g = sns.kdeplot(self.input_data[col], palette=palette, alpha=0.6, shade=True)\n",
        "            g.set_xlabel(col)\n",
        "            # g.set_ylabel(\"Frequency\")\n",
        "            # g = g.legend([\"No Diesese\", \"Diesese\"])\n",
        "            count += 1\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_figure:\n",
        "            save_figure_to_disk(main_folder=self.stage, figure_name= self.fig_title , save_as_plt = True)\n",
        "        \n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad9b52f",
      "metadata": {
        "id": "cad9b52f"
      },
      "outputs": [],
      "source": [
        "class BarPlots(Figures):\n",
        "    \n",
        "    def order_keys_values(self):\n",
        "\n",
        "        if type(self.input_data) == dict:\n",
        "            self.input_data = dict(sorted(self.input_data.items(), key=lambda x: (x[1], x[0]), reverse=self.asc))\n",
        "            keys = list(self.input_data.keys())\n",
        "            values = list(self.input_data.values())\n",
        "            return keys, values\n",
        "\n",
        "        elif type(self.input_data) == pd.core.frame.DataFrame:\n",
        "            keys = list(self.input_data.index)\n",
        "            values = list(self.input_data.importance)\n",
        "            return keys, values\n",
        "    \n",
        "    def horizontal_barplot(self, figsize=(12, 7), color='firebrick',save_figure=False):\n",
        "\n",
        "        keys, values = self.order_keys_values()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax.barh(y=keys, width=values, align='center', color=color, alpha=0.6)\n",
        "        ax.set_yticklabels(keys)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_xlabel(self.y_title)\n",
        "        ax.set_ylabel(self.x_title)\n",
        "        ax.set_title(self.fig_title)\n",
        "        if save_figure:\n",
        "            save_figure_to_disk(main_folder=self.stage, figure_name= self.fig_title , save_as_plt = True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def vertical_barplot(self, figsize=(12, 7), color='firebrick',save_figure=False):\n",
        "\n",
        "        keys, values = self.order_keys_values()\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.bar(x=keys, height=values, color=color, width=0.4, alpha=0.6)\n",
        "\n",
        "        plt.title(self.fig_title)\n",
        "        plt.xlabel(self.x_title)\n",
        "        plt.ylabel(self.y_title)\n",
        "        \n",
        "        if save_figure:\n",
        "            save_figure_to_disk(main_folder=self.stage, figure_name= self.fig_title , save_as_plt = True)\n",
        "        plt.show()\n",
        "\n",
        "    def count_plots(self, cols = list, palette=None, figsize=(14, 48), save_figure=False ):\n",
        "        cols = cols if type(cols) is list else [cols]\n",
        "        plt.figure(figsize=figsize)\n",
        "        count = 1\n",
        "        \n",
        "        for col in cols:\n",
        "            count += 1\n",
        "            plt.subplot(9, 2, count)\n",
        "            sns.countplot(y=col, data=self.input_data, alpha=0.6, order=self.input_data[col].value_counts().index, palette=palette)\n",
        "            count += 1\n",
        "            \n",
        "        if save_figure:\n",
        "            save_figure_to_disk(main_folder=self.stage, figure_name= self.fig_title , save_as_plt = True)\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "d = {'a':435454,'b':93849834,'c':93849834}\n",
        "#         self.input_data = input_data\n",
        "#         self.target_label = target_label\n",
        "#         self.asc = asc\n",
        "#         self.fig_title = fig_title\n",
        "#         self.x_title = x_title\n",
        "#         self.y_title = y_title\n",
        "#         self.stage = stage\n",
        "     \n",
        "b = BarPlots(scores ,target_label=target_label, fig_title='barplot',stage= 'Exploratory Data Analysis')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8908e1e",
      "metadata": {
        "id": "e8908e1e"
      },
      "source": [
        "## get_probabilities_per_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8af591",
      "metadata": {
        "id": "ec8af591",
        "outputId": "aa34e077-5555-402b-b19f-76da81f3099d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END  accuracy: (test=0.293) f1_score: (test=0.246) precision_score: (test=0.272) recall_score: (test=0.246) total time=   0.0s\n",
            "[CV] END  accuracy: (test=0.590) f1_score: (test=0.408) precision_score: (test=0.428) recall_score: (test=0.403) total time=   0.8s\n",
            "[CV] END  accuracy: (test=0.473) f1_score: (test=0.303) precision_score: (test=0.328) recall_score: (test=0.334) total time=   0.5s\n",
            "[CV] END  accuracy: (test=0.498) f1_score: (test=0.355) precision_score: (test=0.372) recall_score: (test=0.357) total time=   2.9s\n",
            "[16:21:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.619) f1_score: (test=0.440) precision_score: (test=0.458) recall_score: (test=0.429) total time=  32.2s\n",
            "[CV] END ................................ score: (test=0.293) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.590) total time=   0.9s\n",
            "[CV] END ................................ score: (test=0.473) total time=   0.3s\n",
            "[16:22:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.590) total time=  39.2s\n",
            "[CV 1/3] END ..................n_estimators=200;, score=0.681 total time=  11.8s\n",
            "[CV 2/3] END ..................n_estimators=300;, score=0.682 total time=  18.5s\n",
            "[CV 3/3] END ..................n_estimators=400;, score=0.679 total time=  30.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END  accuracy: (test=0.407) f1_score: (test=0.240) precision_score: (test=0.257) recall_score: (test=0.237) total time=   0.1s\n",
            "[CV] END  accuracy: (test=0.363) f1_score: (test=0.291) precision_score: (test=0.304) recall_score: (test=0.315) total time=   0.0s\n",
            "[CV] END  accuracy: (test=0.526) f1_score: (test=0.309) precision_score: (test=0.344) recall_score: (test=0.302) total time=   0.2s\n",
            "[CV] END  accuracy: (test=0.616) f1_score: (test=0.428) precision_score: (test=0.476) recall_score: (test=0.415) total time=   0.8s\n",
            "[16:21:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.625) f1_score: (test=0.440) precision_score: (test=0.459) recall_score: (test=0.430) total time=   4.3s\n",
            "[CV] END  accuracy: (test=0.524) f1_score: (test=0.363) precision_score: (test=0.369) recall_score: (test=0.376) total time=   3.0s\n",
            "[16:21:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.616) f1_score: (test=0.439) precision_score: (test=0.457) recall_score: (test=0.431) total time=  31.8s\n",
            "[CV] END ................................ score: (test=0.411) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.360) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.495) total time=   0.2s\n",
            "[CV] END ................................ score: (test=0.628) total time=   0.8s\n",
            "[16:22:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.625) total time=   9.1s\n",
            "[CV] END ................................ score: (test=0.524) total time=   3.8s\n",
            "[CV 1/3] END ..................n_estimators=100;, score=0.678 total time=   5.3s\n",
            "[CV 2/3] END ..................n_estimators=200;, score=0.680 total time=  11.7s\n",
            "[CV 3/3] END ..................n_estimators=300;, score=0.678 total time=  19.8s\n",
            "[CV 1/3] END ..................n_estimators=500;, score=0.685 total time=  32.7s\n",
            "[CV] END  accuracy: (test=0.411) f1_score: (test=0.240) precision_score: (test=0.274) recall_score: (test=0.233) total time=   0.1s\n",
            "[CV] END  accuracy: (test=0.360) f1_score: (test=0.271) precision_score: (test=0.286) recall_score: (test=0.319) total time=   0.0s\n",
            "[CV] END  accuracy: (test=0.495) f1_score: (test=0.293) precision_score: (test=0.420) recall_score: (test=0.304) total time=   0.2s\n",
            "[16:21:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.605) f1_score: (test=0.403) precision_score: (test=0.420) recall_score: (test=0.406) total time=   4.9s\n",
            "[CV] END  accuracy: (test=0.456) f1_score: (test=0.166) precision_score: (test=0.163) recall_score: (test=0.194) total time=   0.5s\n",
            "[CV] END  accuracy: (test=0.538) f1_score: (test=0.376) precision_score: (test=0.380) recall_score: (test=0.374) total time=   3.0s\n",
            "[CV] END ................................ score: (test=0.407) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.491) total time=   0.2s\n",
            "[CV] END ................................ score: (test=0.616) total time=   0.9s\n",
            "[16:22:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.634) total time=   9.2s\n",
            "[CV] END ................................ score: (test=0.471) total time=   0.4s\n",
            "[CV] END ................................ score: (test=0.538) total time=   3.8s\n",
            "[16:22:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.625) total time=  40.0s\n",
            "[CV 2/3] END ..................n_estimators=100;, score=0.683 total time=   5.5s\n",
            "[CV 3/3] END ..................n_estimators=200;, score=0.672 total time=  11.7s\n",
            "[CV 1/3] END ..................n_estimators=400;, score=0.683 total time=  25.9s\n",
            "[CV 2/3] END ..................n_estimators=500;, score=0.684 total time=  30.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/Users/carlosdelacruz/miniconda3/envs/autopilot_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END  accuracy: (test=0.393) f1_score: (test=0.240) precision_score: (test=0.268) recall_score: (test=0.245) total time=   0.1s\n",
            "[CV] END  accuracy: (test=0.491) f1_score: (test=0.298) precision_score: (test=0.301) recall_score: (test=0.305) total time=   0.2s\n",
            "[CV] END  accuracy: (test=0.628) f1_score: (test=0.430) precision_score: (test=0.478) recall_score: (test=0.416) total time=   0.8s\n",
            "[16:21:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.634) f1_score: (test=0.449) precision_score: (test=0.460) recall_score: (test=0.441) total time=   5.1s\n",
            "[CV] END  accuracy: (test=0.471) f1_score: (test=0.196) precision_score: (test=0.202) recall_score: (test=0.215) total time=   0.5s\n",
            "[16:21:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:21:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END  accuracy: (test=0.590) f1_score: (test=0.392) precision_score: (test=0.420) recall_score: (test=0.390) total time=  32.5s\n",
            "[CV] END ................................ score: (test=0.393) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.363) total time=   0.0s\n",
            "[CV] END ................................ score: (test=0.526) total time=   0.2s\n",
            "[16:22:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.605) total time=   9.1s\n",
            "[CV] END ................................ score: (test=0.456) total time=   0.3s\n",
            "[CV] END ................................ score: (test=0.498) total time=   3.7s\n",
            "[16:22:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[16:23:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[CV] END ................................ score: (test=0.610) total time=  39.9s\n",
            "[CV 3/3] END ..................n_estimators=100;, score=0.677 total time=   5.4s\n",
            "[CV 1/3] END ..................n_estimators=300;, score=0.688 total time=  17.2s\n",
            "[CV 2/3] END ..................n_estimators=400;, score=0.686 total time=  29.3s\n",
            "[CV 3/3] END ..................n_estimators=500;, score=0.684 total time=  24.5s\n"
          ]
        }
      ],
      "source": [
        "# UPDATE THIS WITH NEW VERSION "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "615116a1",
      "metadata": {
        "id": "615116a1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0679947",
      "metadata": {
        "id": "e0679947"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29beebe6",
      "metadata": {
        "id": "29beebe6"
      },
      "source": [
        "##  Learning to Rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04cbf63",
      "metadata": {
        "id": "a04cbf63",
        "outputId": "262dec8f-10fc-48c2-9b57-69c5dac2cada"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/by/pt5_hysn0lb75x63vpgqbtsw0000gn/T/ipykernel_19847/797355198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df['id'])\n",
        "\n",
        "X_train_inds, X_test_inds = next(gss)\n",
        "\n",
        "train_data= df.iloc[X_train_inds]\n",
        "X_train = train_data.loc[:, ~train_data.columns.isin(['id','rank'])]\n",
        "y_train = train_data.loc[:, train_data.columns.isin(['rank'])]\n",
        "\n",
        "test_data= df.iloc[X_test_inds]\n",
        "\n",
        "#We need to keep the id for later predictions\n",
        "X_test = test_data.loc[:, ~test_data.columns.isin(['rank'])]\n",
        "y_test = test_data.loc[:, test_data.columns.isin(['rank'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd948fe",
      "metadata": {
        "id": "2dd948fe",
        "outputId": "0d263f7b-f109-48ad-8f6a-09c066f58036"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/by/pt5_hysn0lb75x63vpgqbtsw0000gn/T/ipykernel_19847/3611264344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df['id'])\n",
        "\n",
        "X_train_inds, X_test_inds = next(gss)\n",
        "\n",
        "train_data= df.iloc[X_train_inds]\n",
        "X_train = train_data.loc[:, ~train_data.columns.isin(['id','rank'])]\n",
        "y_train = train_data.loc[:, train_data.columns.isin(['rank'])]\n",
        "\n",
        "groups = train_data.groupby('id').size().to_frame('size')['size'].to_numpy()\n",
        "\n",
        "test_data= df.iloc[X_test_inds]\n",
        "\n",
        "#We need to keep the id for later predictions\n",
        "X_test = test_data.loc[:, ~test_data.columns.isin(['rank'])]\n",
        "y_test = test_data.loc[:, test_data.columns.isin(['rank'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209c20d7",
      "metadata": {
        "id": "209c20d7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebac5f72",
      "metadata": {
        "id": "ebac5f72"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e77eb6",
      "metadata": {
        "id": "14e77eb6"
      },
      "source": [
        "## AutoEncoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0bd1ca",
      "metadata": {
        "id": "5c0bd1ca"
      },
      "outputs": [],
      "source": [
        "X_train,X_test, y_train, y_test = get_splits_wrapper(dataframe = samp_df_encoded, target_label = 'Segment', train_split=True\n",
        "                       ,validation_set=False , test_size = 0.2 , scaled=True,scaler=MinMaxScaler() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d214b47",
      "metadata": {
        "id": "6d214b47",
        "outputId": "ff164f40-680e-4ea2-87c1-26ccb51e80cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "150/150 [==============================] - 2s 6ms/step - loss: 0.0959 - accuracy: 0.2488 - val_loss: 0.0881 - val_accuracy: 0.1767\n",
            "Epoch 2/200\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.3167 - val_loss: 0.0340 - val_accuracy: 0.2317\n",
            "Epoch 3/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.3375 - val_loss: 0.0155 - val_accuracy: 0.2483\n",
            "Epoch 4/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.3483 - val_loss: 0.0116 - val_accuracy: 0.2483\n",
            "Epoch 5/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.3458 - val_loss: 0.0110 - val_accuracy: 0.3317\n",
            "Epoch 6/200\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0163 - accuracy: 0.3346 - val_loss: 0.0108 - val_accuracy: 0.3867\n",
            "Epoch 7/200\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.3638 - val_loss: 0.0110 - val_accuracy: 0.4583\n",
            "Epoch 8/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.3613 - val_loss: 0.0086 - val_accuracy: 0.3100\n",
            "Epoch 9/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.3654 - val_loss: 0.0088 - val_accuracy: 0.3800\n",
            "Epoch 10/200\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.3625 - val_loss: 0.0080 - val_accuracy: 0.4133\n",
            "Epoch 00010: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def encoder(X_train, X_test, epochs = 200, batch_size=32 , optimizer= 'adam', verbose= 1, patience= 3):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    input_n = X_train.shape[1]\n",
        "    param_test = 10\n",
        "  \n",
        "    # define encoder\n",
        "    visible = Input(shape = (input_n,))\n",
        "    \n",
        "    encoder = Dense(input_n*param_test)(visible)\n",
        "    encoder = BatchNormalization()(encoder)\n",
        "    encoder= LeakyReLU()(encoder)\n",
        "    \n",
        "    encoder = Dense(input_n)(encoder)\n",
        "    encoder = BatchNormalization()(encoder)\n",
        "    encoder = LeakyReLU()(encoder)\n",
        "\n",
        "    n_bottleneck = round(float(input_n) / 2.0)\n",
        "    bottleneck = Dense(n_bottleneck)(encoder)\n",
        "    \n",
        "    # define decoder \n",
        "    decoder = Dense(input_n)(bottleneck)\n",
        "    decoder = BatchNormalization()(decoder)\n",
        "    decoder = LeakyReLU()(decoder)\n",
        "    \n",
        "    decoder= Dense(input_n*param_test)(decoder)\n",
        "    decoder = BatchNormalization()(decoder)\n",
        "    decoder= LeakyReLU()(decoder)\n",
        "    \n",
        "    output = Dense(input_n, activation='linear')(decoder)\n",
        "    \n",
        "    model = Model(inputs=visible, outputs=output)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics = ['accuracy']  )\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor = 'val_accuracy', mode ='max', verbose = verbose, patience = patience)\n",
        "    \n",
        "    history = model.fit(X_train, X_train, epochs = epochs, callbacks = [early_stop], batch_size= batch_size, \n",
        "                        verbose = verbose, \n",
        "                        validation_data=(X_test,X_test))\n",
        "    \n",
        "    encoder = Model(inputs=visible, outputs=bottleneck)\n",
        "    \n",
        "    return encoder\n",
        "\n",
        "encoder_model = encoder(X_train, X_test, epochs = 200, batch_size=16 , verbose= 1, patience= 3  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c3ce7f",
      "metadata": {
        "id": "67c3ce7f"
      },
      "outputs": [],
      "source": [
        "# encode the test and train data\n",
        "\n",
        "X_train_encode = encoder_model.predict(X_train)\n",
        "\n",
        "X_test_encode = encoder_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2bbb42a",
      "metadata": {
        "id": "f2bbb42a",
        "outputId": "b9348835-4fe6-4532-93cc-469c0c56c4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.49166666666666664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "model1 = LogisticRegression()\n",
        "model2 = XGBClassifier()\n",
        "model = model1\n",
        "# fit the model on the training set\n",
        "\n",
        "model.fit(X_train_encode, y_train)\n",
        "# make predictions on the test set\n",
        "yhat = model.predict(X_test_encode)\n",
        "# calculate classification accuracy\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a3470a",
      "metadata": {
        "scrolled": false,
        "id": "46a3470a",
        "outputId": "c67e8799-b5a2-40d9-eb92-9b1c92483df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5383333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carlosdelacruz/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "# make predictions on the test set\n",
        "yhat = model.predict(X_test)\n",
        "# calculate classification accuracy\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "autopilot_env",
      "language": "python",
      "name": "autopilot_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "debug_funcs.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}